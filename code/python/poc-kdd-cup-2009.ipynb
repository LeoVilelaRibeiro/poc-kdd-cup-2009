{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection, ensemble, tree, neighbors, svm, linear_model, metrics, externals\n",
    "from fancyimpute import SoftImpute\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções e Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "# Lista de modelos\n",
    "modelos = [\n",
    "    ensemble.GradientBoostingClassifier,\n",
    "    ensemble.RandomForestClassifier,\n",
    "    tree.DecisionTreeClassifier,\n",
    "    neighbors.KNeighborsClassifier,\n",
    "    svm.LinearSVC,\n",
    "    linear_model.SGDClassifier\n",
    "]\n",
    "\n",
    "def fnc_Dummies(df):\n",
    "    for cat_feature in df.select_dtypes(include=['object']).columns:\n",
    "        df[cat_feature] = pd.Categorical(df[cat_feature]).codes\n",
    "        df[cat_feature] = df[cat_feature].replace(-1,np.nan)\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "def fnc_Imputer(df):\n",
    "    imp_cols = df.columns.values\n",
    "    imputer = SoftImpute()\n",
    "    return pd.DataFrame(imputer.fit_transform(df), columns= imp_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small_df\n",
    "df_small_train = pd.read_csv(zipfile.ZipFile('../../dist/orange_small_train.data.zip').open('orange_small_train.data'),sep='\\t')\n",
    "df_small_test = pd.read_csv(zipfile.ZipFile('../../dist/orange_small_test.data.zip').open('orange_small_test.data'),sep='\\t')\n",
    "\n",
    "# labels\n",
    "df_small_train['appetency'] = pd.read_csv('../../dist/orange_small_train_appetency.labels',header = None)\n",
    "df_small_train['churn'] = pd.read_csv('../../dist/orange_small_train_churn.labels',header = None)\n",
    "df_small_train['upselling'] = pd.read_csv('../../dist/orange_small_train_upselling.labels',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning, Preparation &  Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  #6 - Selecionar fatos com 30%+ de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_small_train.copy()\n",
    "df_v2 = df[[column for column in df if df[column].count() / len(df) >= 0.3]]\n",
    "\n",
    "print(\"Lista de fatos excluídos:\", end=\" \")\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in df_v2.columns:\n",
    "        print(c, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #7 - Criação de dummies para modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v3 = df_v2.copy()\n",
    "df_v3 = fnc_Dummies(df_v3)\n",
    "df_v3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #8 - Tratamento de missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4 = fnc_Imputer(df_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #9 - Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4.hist(figsize=(32, 40), bins=50, xlabelsize=8, ylabelsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #10 - Regressão linear (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_analyse = df_v4.columns\n",
    "\n",
    "# fig, ax = plt.subplots(round(len(features_to_analyse) / 3), 3, figsize = (32,40))\n",
    "\n",
    "# for i, ax in enumerate(fig.axes):\n",
    "#     if i < len(features_to_analyse) - 1:\n",
    "#         sns.regplot(x=features_to_analyse[i],y='appetency', data=df_v4[features_to_analyse], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #11 - Matriz de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_v4.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,annot=False, annot_kws={\"size\": 8}, \n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_interesse = corr[['appetency','churn','upselling']]\n",
    "var_interesse = var_interesse.drop(['appetency','churn','upselling'])\n",
    "var_interesse.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection & Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Max Singular Value of X_init = 1894274017.137738\n",
      "[SoftImpute] Iter 1: observed MAE=13528.223716 rank=8\n",
      "[SoftImpute] Iter 2: observed MAE=13560.363389 rank=8\n",
      "[SoftImpute] Iter 3: observed MAE=13574.810176 rank=8\n",
      "[SoftImpute] Iter 4: observed MAE=13580.071444 rank=8\n",
      "[SoftImpute] Iter 5: observed MAE=13581.954786 rank=8\n",
      "[SoftImpute] Iter 6: observed MAE=13582.674033 rank=8\n",
      "[SoftImpute] Iter 7: observed MAE=13582.995111 rank=8\n",
      "[SoftImpute] Iter 8: observed MAE=13583.175751 rank=8\n",
      "[SoftImpute] Iter 9: observed MAE=13583.302025 rank=8\n",
      "[SoftImpute] Iter 10: observed MAE=13583.404055 rank=8\n",
      "[SoftImpute] Iter 11: observed MAE=13583.492870 rank=8\n",
      "[SoftImpute] Iter 12: observed MAE=13583.573099 rank=8\n",
      "[SoftImpute] Iter 13: observed MAE=13583.646964 rank=8\n",
      "[SoftImpute] Iter 14: observed MAE=13583.715589 rank=8\n",
      "[SoftImpute] Iter 15: observed MAE=13583.779761 rank=8\n",
      "[SoftImpute] Iter 16: observed MAE=13583.840086 rank=8\n",
      "[SoftImpute] Iter 17: observed MAE=13583.896994 rank=8\n",
      "[SoftImpute] Iter 18: observed MAE=13583.950920 rank=8\n",
      "[SoftImpute] Iter 19: observed MAE=13584.002233 rank=8\n",
      "[SoftImpute] Iter 20: observed MAE=13584.051318 rank=8\n",
      "[SoftImpute] Iter 21: observed MAE=13584.098366 rank=8\n",
      "[SoftImpute] Iter 22: observed MAE=13584.143553 rank=8\n",
      "[SoftImpute] Iter 23: observed MAE=13584.187036 rank=8\n",
      "[SoftImpute] Iter 24: observed MAE=13584.228996 rank=8\n",
      "[SoftImpute] Iter 25: observed MAE=13584.269567 rank=8\n",
      "[SoftImpute] Iter 26: observed MAE=13584.308876 rank=8\n",
      "[SoftImpute] Iter 27: observed MAE=13584.347017 rank=8\n",
      "[SoftImpute] Iter 28: observed MAE=13584.384057 rank=8\n",
      "[SoftImpute] Iter 29: observed MAE=13584.420081 rank=8\n",
      "[SoftImpute] Iter 30: observed MAE=13584.455123 rank=8\n",
      "[SoftImpute] Iter 31: observed MAE=13584.489248 rank=8\n",
      "[SoftImpute] Iter 32: observed MAE=13584.522510 rank=8\n",
      "[SoftImpute] Iter 33: observed MAE=13584.554948 rank=8\n",
      "[SoftImpute] Iter 34: observed MAE=13584.586613 rank=8\n",
      "[SoftImpute] Iter 35: observed MAE=13584.617568 rank=8\n",
      "[SoftImpute] Iter 36: observed MAE=13584.647820 rank=8\n",
      "[SoftImpute] Iter 37: observed MAE=13584.677408 rank=8\n",
      "[SoftImpute] Iter 38: observed MAE=13584.706324 rank=8\n",
      "[SoftImpute] Iter 39: observed MAE=13584.734600 rank=8\n",
      "[SoftImpute] Iter 40: observed MAE=13584.762306 rank=8\n",
      "[SoftImpute] Iter 41: observed MAE=13584.789430 rank=8\n",
      "[SoftImpute] Iter 42: observed MAE=13584.815973 rank=8\n",
      "[SoftImpute] Iter 43: observed MAE=13584.841967 rank=8\n",
      "[SoftImpute] Iter 44: observed MAE=13584.867414 rank=8\n",
      "[SoftImpute] Iter 45: observed MAE=13584.892352 rank=8\n",
      "[SoftImpute] Iter 46: observed MAE=13584.916779 rank=8\n",
      "[SoftImpute] Iter 47: observed MAE=13584.940725 rank=8\n",
      "[SoftImpute] Iter 48: observed MAE=13584.964223 rank=8\n",
      "[SoftImpute] Iter 49: observed MAE=13584.987277 rank=8\n",
      "[SoftImpute] Iter 50: observed MAE=13585.009861 rank=8\n",
      "[SoftImpute] Iter 51: observed MAE=13585.032001 rank=8\n",
      "[SoftImpute] Iter 52: observed MAE=13585.053714 rank=8\n",
      "[SoftImpute] Iter 53: observed MAE=13585.075007 rank=8\n",
      "[SoftImpute] Iter 54: observed MAE=13585.095894 rank=8\n",
      "[SoftImpute] Iter 55: observed MAE=13585.116399 rank=8\n",
      "[SoftImpute] Iter 56: observed MAE=13585.136508 rank=8\n",
      "[SoftImpute] Iter 57: observed MAE=13585.156230 rank=8\n",
      "[SoftImpute] Iter 58: observed MAE=13585.175575 rank=8\n",
      "[SoftImpute] Iter 59: observed MAE=13585.194566 rank=8\n",
      "[SoftImpute] Iter 60: observed MAE=13585.213205 rank=8\n",
      "[SoftImpute] Iter 61: observed MAE=13585.231485 rank=8\n",
      "[SoftImpute] Iter 62: observed MAE=13585.249420 rank=8\n",
      "[SoftImpute] Iter 63: observed MAE=13585.267008 rank=8\n",
      "[SoftImpute] Iter 64: observed MAE=13585.284265 rank=8\n",
      "[SoftImpute] Iter 65: observed MAE=13585.301204 rank=8\n",
      "[SoftImpute] Iter 66: observed MAE=13585.317842 rank=8\n",
      "[SoftImpute] Iter 67: observed MAE=13585.334178 rank=8\n",
      "[SoftImpute] Iter 68: observed MAE=13585.350200 rank=8\n",
      "[SoftImpute] Iter 69: observed MAE=13585.365924 rank=8\n",
      "[SoftImpute] Iter 70: observed MAE=13585.381353 rank=8\n",
      "[SoftImpute] Iter 71: observed MAE=13585.396491 rank=8\n",
      "[SoftImpute] Iter 72: observed MAE=13585.411339 rank=8\n",
      "[SoftImpute] Iter 73: observed MAE=13585.425914 rank=8\n",
      "[SoftImpute] Iter 74: observed MAE=13585.440217 rank=8\n",
      "[SoftImpute] Iter 75: observed MAE=13585.454259 rank=8\n",
      "[SoftImpute] Iter 76: observed MAE=13585.468049 rank=8\n",
      "[SoftImpute] Iter 77: observed MAE=13585.481589 rank=8\n",
      "[SoftImpute] Iter 78: observed MAE=13585.494876 rank=8\n",
      "[SoftImpute] Iter 79: observed MAE=13585.507912 rank=8\n",
      "[SoftImpute] Iter 80: observed MAE=13585.520700 rank=8\n",
      "[SoftImpute] Iter 81: observed MAE=13585.533251 rank=8\n",
      "[SoftImpute] Iter 82: observed MAE=13585.545565 rank=8\n",
      "[SoftImpute] Iter 83: observed MAE=13585.557649 rank=8\n",
      "[SoftImpute] Iter 84: observed MAE=13585.569501 rank=8\n",
      "[SoftImpute] Iter 85: observed MAE=13585.581125 rank=8\n",
      "[SoftImpute] Iter 86: observed MAE=13585.592527 rank=8\n",
      "[SoftImpute] Iter 87: observed MAE=13585.603714 rank=8\n",
      "[SoftImpute] Iter 88: observed MAE=13585.614691 rank=8\n",
      "[SoftImpute] Iter 89: observed MAE=13585.625462 rank=8\n",
      "[SoftImpute] Iter 90: observed MAE=13585.636029 rank=8\n",
      "[SoftImpute] Iter 91: observed MAE=13585.646399 rank=8\n",
      "[SoftImpute] Iter 92: observed MAE=13585.656585 rank=8\n",
      "[SoftImpute] Iter 93: observed MAE=13585.666578 rank=8\n",
      "[SoftImpute] Iter 94: observed MAE=13585.676382 rank=8\n",
      "[SoftImpute] Iter 95: observed MAE=13585.686004 rank=8\n",
      "[SoftImpute] Iter 96: observed MAE=13585.695446 rank=8\n",
      "[SoftImpute] Iter 97: observed MAE=13585.704711 rank=8\n",
      "[SoftImpute] Iter 98: observed MAE=13585.713801 rank=8\n",
      "[SoftImpute] Iter 99: observed MAE=13585.722717 rank=8\n",
      "[SoftImpute] Iter 100: observed MAE=13585.731466 rank=8\n",
      "[SoftImpute] Stopped after iteration 100 for lambda=37885480.342755\n",
      "====================================================================================================\n",
      "appetency\n",
      "====================================================================================================\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "Mean score:  0.9814399999999999 / Std Score:  0.00041761226035642385\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "Mean score:  0.9821399999999999 / Std Score:  9.165151389910671e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "Mean score:  0.9610800000000002 / Std Score:  0.0015104966070799185\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "Mean score:  0.9821200000000001 / Std Score:  9.797958971131634e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "Mean score:  0.75632 / Std Score:  0.21127588030818853\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n",
      "Mean score:  0.96724 / Std Score:  0.020152379512107247\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "churn\n",
      "====================================================================================================\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n"
     ]
    }
   ],
   "source": [
    "# Preparar dataset para treinos\n",
    "df_v5 = df_v4.copy()\n",
    "\n",
    "lista_var_interesse = ['appetency','churn','upselling']\n",
    "\n",
    "del df_v5['appetency']\n",
    "del df_v5['churn']\n",
    "del df_v5['upselling']\n",
    "\n",
    "# Prepara dataset de test\n",
    "df_test = df_small_test[df_v5.columns]\n",
    "df_test = fnc_Imputer(fnc_Dummies(df_test))\n",
    "\n",
    "# Lista de resultados\n",
    "resultados = [['status','var','model','mean','std','time','scores','caminho']]\n",
    "lista_modelos = []\n",
    "\n",
    "# Score dos modelos\n",
    "for var_interesse in lista_var_interesse:\n",
    "    print('='*100)\n",
    "    print(var_interesse)\n",
    "    print('='*100)\n",
    "    \n",
    "    Y = df_v4[[var_interesse]].values.ravel()\n",
    "    for var in modelos:\n",
    "        start = time.time()\n",
    "        try:\n",
    "            filename = str('../../models/'+var_interesse+'_'+var.__name__+'.model')\n",
    "            print(var)\n",
    "            clf = var()\n",
    "            \n",
    "            # Calcula o score\n",
    "            scores = model_selection.cross_val_score(clf, df_v5, Y, cv=10, error_score='raise')\n",
    "            print('Mean score: ',np.mean(scores), '/ Std Score: ',np.std(scores))\n",
    "            resultados.append(['ok',var_interesse,var.__name__,np.mean(scores),np.std(scores),time.time() - start,scores,filename])\n",
    "            \n",
    "            # Salva modelo            \n",
    "            model = clf.fit(df_v5, Y)\n",
    "            externals.joblib.dump(model,filename)\n",
    "                \n",
    "        except(Exception):\n",
    "            print('>> Validar parâmetros.')\n",
    "            resultados.append(['erro',var_interesse,var.__name__,None,None,time.time() - start,None,None])\n",
    "            pass\n",
    "        finally:            \n",
    "            print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('../../dist/resultados_modelos.xlsx', engine='xlsxwriter')\n",
    "df_final = pd.DataFrame(resultados[1:])\n",
    "df_final.columns = resultados[0]\n",
    "df_final.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sort_values(by=['var','mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #14 - Comparação de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1, 1, 2, 2])\n",
    "pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
