{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection, ensemble, tree, neighbors, gaussian_process\n",
    "from fancyimpute import SoftImpute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções e Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "# Lista de modelos\n",
    "modelos = [\n",
    "    ensemble.GradientBoostingClassifier,\n",
    "    ensemble.RandomForestClassifier,\n",
    "    tree.DecisionTreeClassifier,\n",
    "    neighbors.KNeighborsClassifier,\n",
    "    gaussian_process.GaussianProcessClassifier\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small_df\n",
    "df_small_train = pd.read_csv(zipfile.ZipFile('../../dist/orange_small_train.data.zip').open('orange_small_train.data'),sep='\\t')\n",
    "df_small_test = pd.read_csv(zipfile.ZipFile('../../dist/orange_small_test.data.zip').open('orange_small_test.data'),sep='\\t')\n",
    "\n",
    "# labels\n",
    "df_small_train['appetency'] = pd.read_csv('../../dist/orange_small_train_appetency.labels',header = None)\n",
    "df_small_train['churn'] = pd.read_csv('../../dist/orange_small_train_churn.labels',header = None)\n",
    "df_small_train['upselling'] = pd.read_csv('../../dist/orange_small_train_upselling.labels',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning, Preparation &  Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  #6 - Selecionar fatos com 30%+ de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_small_train.copy()\n",
    "df_v2 = df[[column for column in df if df[column].count() / len(df) >= 0.3]]\n",
    "\n",
    "print(\"Lista de fatos excluídos:\", end=\" \")\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in df_v2.columns:\n",
    "        print(c, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #7 - Criação de dummies para modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_v2.iloc[0:100].copy()\n",
    "df_v3 = df_v2.copy()\n",
    "\n",
    "for cat_feature in df_v3.select_dtypes(include=['object']).columns:\n",
    "    df_v3[cat_feature] = pd.Categorical(df_v3[cat_feature]).codes\n",
    "    df_v3[cat_feature] = df_v3[cat_feature].replace(-1,np.nan)\n",
    "    \n",
    "df_v3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #8 - Tratamento de missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols = df_v3.columns.values\n",
    "imputer = SoftImpute()\n",
    "df_v4 = pd.DataFrame(imputer.fit_transform(df_v3), columns= imp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #9 - Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4.hist(figsize=(32, 40), bins=50, xlabelsize=8, ylabelsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #10 - Regressão linear (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_analyse = df_v4.columns\n",
    "\n",
    "# fig, ax = plt.subplots(round(len(features_to_analyse) / 3), 3, figsize = (32,40))\n",
    "\n",
    "# for i, ax in enumerate(fig.axes):\n",
    "#     if i < len(features_to_analyse) - 1:\n",
    "#         sns.regplot(x=features_to_analyse[i],y='appetency', data=df_v4[features_to_analyse], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #11 - Matriz de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_v4.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,annot=False, annot_kws={\"size\": 8}, \n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_interesse = corr[['appetency','churn','upselling']]\n",
    "var_interesse = var_interesse.drop(['appetency','churn','upselling'])\n",
    "var_interesse.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection & Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dataset para treinos\n",
    "df_v5 = df_v4.copy()\n",
    "\n",
    "lista_var_interesse = ['appetency','churn','upselling']\n",
    "\n",
    "del df_v5['appetency']\n",
    "del df_v5['churn']\n",
    "del df_v5['upselling']\n",
    "\n",
    "# Lista de resultados\n",
    "resultados = [['status','model','mean','std','time']]\n",
    "\n",
    "# Score dos modelos\n",
    "for var_interesse in lista_var_interesse:\n",
    "    print('='*100)\n",
    "    print(var_interesse)\n",
    "    print('='*100)\n",
    "    \n",
    "    Y = df_v4[[var_interesse]].values.ravel()\n",
    "    for var in modelos:\n",
    "        start = time.time()\n",
    "        try:\n",
    "            print(var)\n",
    "            clf = var()\n",
    "            scores = model_selection.cross_val_score(clf, df_v5, Y, cv=10, error_score='raise')\n",
    "            print('Mean score: ',np.mean(scores), '/ Std Score: ',np.std(scores))\n",
    "            resultados.append(['ok',var.__name__,np.mean(scores),np.std(scores),time.time() - start])\n",
    "        except(Exception):\n",
    "            print('>> Validar parâmetros.')\n",
    "            resultados.append(['erro',var.__name__,None,None,time.time() - start])\n",
    "            pass\n",
    "        finally:            \n",
    "            print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('../../dist/resultados_modelos.xlsx', engine='xlsxwriter')\n",
    "df_final = pd.DataFrame(resultados[1:])\n",
    "df_final.columns = resultados[0]\n",
    "df_final.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sort_values(by='mean', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
