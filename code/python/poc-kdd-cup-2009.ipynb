{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection, ensemble, tree, neighbors, svm, linear_model, metrics, externals\n",
    "from fancyimpute import SoftImpute\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções e Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de modelos\n",
    "modelos = [\n",
    "    ensemble.GradientBoostingClassifier,\n",
    "    ensemble.RandomForestClassifier,\n",
    "    tree.DecisionTreeClassifier,\n",
    "    neighbors.KNeighborsClassifier,\n",
    "    svm.LinearSVC,\n",
    "    linear_model.SGDClassifier\n",
    "]\n",
    "\n",
    "def fnc_Dummies(df):\n",
    "    for cat_feature in df.select_dtypes(include=['object']).columns:\n",
    "        df[cat_feature] = pd.Categorical(df[cat_feature]).codes\n",
    "        df[cat_feature] = df[cat_feature].replace(-1,np.nan)\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "def fnc_Imputer(df):\n",
    "    imp_cols = df.columns.values\n",
    "    imputer = SoftImpute()\n",
    "    return pd.DataFrame(imputer.fit_transform(df), columns= imp_cols)\n",
    "\n",
    "def fnc_UAC(y,pred):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small_df\n",
    "df_small_train = pd.read_csv(zipfile.ZipFile('../../dist/orange_small_train.data.zip').open('orange_small_train.data'),sep='\\t')\n",
    "df_small_test = pd.read_csv(zipfile.ZipFile('../../dist/orange_small_test.data.zip').open('orange_small_test.data'),sep='\\t')\n",
    "\n",
    "# labels\n",
    "df_small_train['appetency'] = pd.read_csv('../../dist/orange_small_train_appetency.labels',header = None)\n",
    "df_small_train['churn'] = pd.read_csv('../../dist/orange_small_train_churn.labels',header = None)\n",
    "df_small_train['upselling'] = pd.read_csv('../../dist/orange_small_train_upselling.labels',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning, Preparation &  Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  #6 - Selecionar fatos com 30%+ de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_small_train.copy()\n",
    "df_v2 = df[[column for column in df if df[column].count() / len(df) >= 0.3]]\n",
    "\n",
    "print(\"Lista de fatos excluídos:\", end=\" \")\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in df_v2.columns:\n",
    "        print(c, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #7 - Criação de dummies para modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v3 = df_v2.copy()\n",
    "df_v3 = fnc_Dummies(df_v3)\n",
    "df_v3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #8 - Tratamento de missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4 = fnc_Imputer(df_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #9 - Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4.hist(figsize=(32, 40), bins=50, xlabelsize=8, ylabelsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #10 - Regressão linear (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_analyse = df_v4.columns\n",
    "\n",
    "# fig, ax = plt.subplots(round(len(features_to_analyse) / 3), 3, figsize = (32,40))\n",
    "\n",
    "# for i, ax in enumerate(fig.axes):\n",
    "#     if i < len(features_to_analyse) - 1:\n",
    "#         sns.regplot(x=features_to_analyse[i],y='appetency', data=df_v4[features_to_analyse], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #11 - Matriz de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_v4.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,annot=False, annot_kws={\"size\": 8}, \n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_interesse = corr[['appetency','churn','upselling']]\n",
    "var_interesse = var_interesse.drop(['appetency','churn','upselling'])\n",
    "var_interesse.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection & Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #12 - Seleção de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dataset para treinos\n",
    "df_v5 = df_v4.copy()\n",
    "\n",
    "lista_var_interesse = ['appetency','churn','upselling']\n",
    "\n",
    "del df_v5['appetency']\n",
    "del df_v5['churn']\n",
    "del df_v5['upselling']\n",
    "\n",
    "# Prepara dataset de test\n",
    "df_test = df_small_test[df_v5.columns]\n",
    "df_test = fnc_Imputer(fnc_Dummies(df_test))\n",
    "\n",
    "# Lista de resultados\n",
    "resultados = [['status','var','model','mean','std','time','scores','caminho']]\n",
    "lista_modelos = []\n",
    "\n",
    "# Score dos modelos\n",
    "for var_interesse in lista_var_interesse:\n",
    "    print('='*100)\n",
    "    print(var_interesse)\n",
    "    print('='*100)\n",
    "    \n",
    "    Y = df_v4[[var_interesse]].values.ravel()\n",
    "    for var in modelos:\n",
    "        start = time.time()\n",
    "        try:\n",
    "            filename = str('../../models/'+var_interesse+'_'+var.__name__+'.model')\n",
    "            print(var)\n",
    "            clf = var()\n",
    "            \n",
    "            # Calcula o score\n",
    "            scores = model_selection.cross_val_score(clf, df_v5, Y, cv=10, error_score='raise')\n",
    "            print('Mean score: ',np.mean(scores), '/ Std Score: ',np.std(scores))\n",
    "            resultados.append(['ok',var_interesse,var.__name__,np.mean(scores),np.std(scores),time.time() - start,scores,filename])\n",
    "            \n",
    "            # Salva modelo            \n",
    "            model = clf.fit(df_v5, Y)\n",
    "            externals.joblib.dump(model,filename)\n",
    "                \n",
    "        except(Exception):\n",
    "            print('>> Validar parâmetros.')\n",
    "            resultados.append(['erro',var_interesse,var.__name__,None,None,time.time() - start,None,None])\n",
    "            pass\n",
    "        finally:            \n",
    "            print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('../../dist/resultados_modelos.xlsx', engine='xlsxwriter')\n",
    "df_final = pd.DataFrame(resultados[1:])\n",
    "df_final.columns = resultados[0]\n",
    "df_final.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sort_values(by=['var','mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #13 - Treinamento e predição de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados\n",
    "predict_results = pd.DataFrame()\n",
    "predict_results['appetency_real'] = df_v4['appetency'].values\n",
    "predict_results['churn_real'] = df_v4['churn'].values\n",
    "predict_results['upselling_real'] = df_v4['upselling'].values\n",
    "\n",
    "for index, row in df_final[['var','model','caminho']].iterrows():\n",
    "    clf = externals.joblib.load(row['caminho'])\n",
    "    predict_results[str(row['var']+'_'+row['model'])] = clf.predict(df_test)\n",
    "\n",
    "predict_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #14 - Comparação de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uac_results = pd.DataFrame(columns=['y','pred','uac'])\n",
    "\n",
    "for index, row in df_final[['var','model','caminho']].iterrows():\n",
    "    y = predict_results[str(row['var']+'_real')]\n",
    "    pred = predict_results[str(row['var']+'_'+row['model'])]    \n",
    "    uac_results = uac_results.append(\n",
    "        pd.Series(\n",
    "        [str(row['var']+'_real'),\n",
    "         str(row['var']+'_'+row['model']),\n",
    "         fnc_UAC(pred=pred,y=y)\n",
    "        ], index=uac_results.columns), \n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "uac_results.sort_values(by=['y','uac'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uac_results = uac_results.sort_values(by=['y','uac'], ascending=False)\n",
    "\n",
    "grafico = sns.barplot(x='y', y='uac',data=uac_results,hue='pred')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.figure(figsize=(500,500))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
